# Firebase RAG PDF Chatbot (Firestore Vector Store) ğŸ“„ğŸ’¬â˜ï¸

This project implements a Retrieval Augmented Generation (RAG) application that allows users to upload PDF documents and engage in a conversational Q&A about their content. The application is built with Python, Langchain, and Google's Gemini Pro model, and is fully hosted on Firebase (Functions, Hosting, Authentication, Cloud Firestore for metadata **and vector embeddings**, and Storage).

## ğŸŒŸ Overview

The core functionality enables users to:
1.  Authenticate securely using Firebase Authentication.
2.  Upload PDF files, which are processed, chunked, and their text embeddings (vectors) are stored in Cloud Firestore.
3.  Ask questions about the content of their uploaded PDFs.
4.  Receive answers generated by Google's Gemini model, augmented with relevant information retrieved by performing similarity search on the vectors stored in Firestore.

This project serves as a practical example of building a serverless, AI-powered document interaction tool using Firestore for vector persistence.

## ğŸ› ï¸ Tech Stack

*   **Backend:**
    *   Python 3.10+
    *   Flask (for serving the application logic within Firebase Functions)
    *   Langchain (for the RAG pipeline, document loading, splitting, and LLM interaction)
    *   Google Generative AI SDK (`langchain-google-genai` for Gemini)
    *   Cloud Firestore (as the primary database for metadata **and storing text vector embeddings**)
*   **Frontend:**
    *   HTML5
    *   CSS3
    *   JavaScript (Vanilla JS for interactions)
*   **Platform & Services:**
    *   **Firebase:**
        *   Firebase Hosting: Serves the static frontend (HTML, CSS, JS).
        *   Firebase Functions: Hosts the Python backend logic (PDF processing, RAG chain, chat, vector generation and retrieval from Firestore).
        *   Firebase Authentication: Manages user sign-up and login (Email/Password, Google Sign-In).
        *   Cloud Firestore: Stores document metadata, processed text chunks, and their corresponding vector embeddings.
        *   Cloud Storage for Firebase: Stores the uploaded PDF documents.
*   **LLM:** Google Gemini (e.g., `gemini-1.5-flash-latest`)
*   **Environment Management:** `python-dotenv` (for local development)

## âœ¨ Features

*   **User Authentication:** Secure sign-in/sign-up for individual user data.
*   **PDF Upload & Processing:** Users can upload PDF files.
*   **Vector Embeddings in Firestore:** Documents are chunked, text is embedded using Google's models, and these vectors are stored directly in Cloud Firestore documents, associated with the user and document.
*   **Conversational Q&A:** Users can ask questions. The system retrieves relevant text chunks by performing similarity search against vectors in Firestore and uses these for context with the Gemini model.
*   **Chat History:** The interface maintains a history of the current conversation.
*   **Data Reset:** Users can reset their uploaded documents and associated vector data from Firestore and Storage.
*   **Serverless Architecture:** Leverages Firebase for a scalable, managed backend.

## ğŸ›ï¸ Architecture

1.  **Frontend (Firebase Hosting):**
    *   Users interact with an HTML/CSS/JS interface.
    *   Firebase Authentication (FirebaseUI) handles login.
    *   User actions (upload, chat, reset) trigger requests to Firebase Functions.
2.  **Firebase Functions (Python Backend):**
    *   **Authentication:** Each request is authenticated using the user's Firebase ID token.
    *   **`/upload_pdf`:**
        *   Receives a PDF file.
        *   Stores the PDF in Firebase Storage (`user_uploads/<UID>/docs/`).
        *   Processes the PDF: chunks the text, generates embeddings for each chunk using Google's embedding model.
        *   Stores each chunk and its vector embedding in Cloud Firestore (e.g., in a subcollection under `users/<UID>/documents/<docID>/chunks/`).
        *   Records overall file metadata in Firestore (`users/<UID>/processed_files/`).
    *   **`/chat`:**
        *   Receives a user query and chat history.
        *   Generates an embedding for the user's query.
        *   Retrieves relevant text chunks for the user by:
            *   Querying Firestore for the user's stored vectors.
            *   Performing a similarity search (e.g., cosine similarity) between the query vector and the stored document vectors. This happens within the Firebase Function. *(Alternatively, this step could involve calling a specialized vector search service or a Firebase extension if integrated).*
        *   Initializes a Langchain `ConversationalRetrievalChain` (or a similar chain) with the Gemini LLM and the retrieved text chunks as context.
        *   Returns the LLM's answer to the frontend.
    *   **`/reset_user_data`:**
        *   Deletes the user's PDFs from Firebase Storage.
        *   Deletes the user's file metadata, text chunks, and vector embeddings from Cloud Firestore.
3.  **Data Storage:**
    *   **Firebase Storage:** Stores raw PDF files (`user_uploads/<UID>/docs/`).
    *   **Cloud Firestore:**
        *   Stores metadata about processed files (`users/<UID>/processed_files/`).
        *   Stores processed text chunks and their vector embeddings (e.g., `users/<UID>/documents/<docID>/chunks/<chunkID>` containing fields like `text_chunk` and `embedding_vector_array`).

## ğŸ“‹ Prerequisites

*   [Node.js and npm](https://nodejs.org/)
*   [Firebase CLI](https://firebase.google.com/docs/cli#install_the_firebase_cli)
*   [Python](https://www.python.org/downloads/) (version 3.10 or higher)
*   A [Google Cloud Platform (GCP) project](https://console.cloud.google.com/) with billing enabled.
*   A [Firebase project](https://console.firebase.google.com/) linked to your GCP project.

## ğŸš€ Setup & Installation

1.  **Clone the Repository:**
    ```bash
    git clone https://github.com/your-username/firebase-rag-chatbot.git
    cd firebase-rag-chatbot
    ```

2.  **Firebase Project Setup:**
    *   Create/select your Firebase project in the [Firebase Console](https://console.firebase.google.com/).
    *   **Enable Services:** Authentication (desired providers), Firestore Database (start in test mode or apply `firestore.rules`), Storage (apply `storage.rules`).
    *   Ensure your project is on the **Blaze (pay-as-you-go)** plan for Cloud Functions.
    *   **Register a Web App:** In Firebase project settings, add a web app and copy the Firebase config object for `public/auth.js`.

3.  **Google Generative AI API Key:**
    *   Obtain an API key for the Gemini API from [Google AI Studio](https://aistudio.google.com/app/apikey) or GCP.

4.  **Backend Setup (`functions/` directory):**
    *   `cd functions`
    *   Create and activate a Python virtual environment:
        ```bash
        python -m venv .venv
        source .venv/bin/activate  # Windows: .venv\Scripts\activate
        ```
    *   Install dependencies: `pip install -r requirements.txt`
        *(Note: `langchain-chroma` might no longer be a direct dependency if not used. Ensure `requirements.txt` reflects the libraries needed for Firestore interaction and vector math, e.g., `numpy` or `scikit-learn` for similarity if done manually).*
    *   Create `functions/.env`:
        ```
        GOOGLE_API_KEY="YOUR_GEMINI_API_KEY"
        ```

5.  **Frontend Setup (`public/auth.js`):**
    *   Open `public/auth.js` and paste your Firebase web app configuration.

6.  **Firebase CLI & Project Linking:**
    *   `firebase login`
    *   (If needed) `firebase init` (select Firestore, Functions, Hosting, Storage; link to your project).

7.  **Firestore Indexes:**
    *   Depending on how you query chunks/vectors (e.g., by user ID, document ID), you may need to define composite indexes in Firestore. Check Firestore console recommendations after deploying and testing.

## ğŸ”§ Local Development & Emulation

1.  **Start Emulators:** From the project root:
    ```bash
    firebase emulators:start
    ```
    Access the frontend at `http://localhost:5000` (or the specified port).
    The Functions emulator will use your `functions/` code. Ensure `GOOGLE_API_KEY` is accessible.

## â˜ï¸ Deployment to Firebase

1.  **Set Firebase Function Environment Variable for API Key:**
    ```bash
    firebase functions:config:set env.google_api_key="YOUR_ACTUAL_GOOGLE_API_KEY"
    ```
    (Your `functions/main.py` looks for `os.environ["GOOGLE_API_KEY"]`).

2.  **Deploy All Firebase Services:**
    From the project root:
    ```bash
    firebase deploy
    ```
    Or deploy parts: `firebase deploy --only functions,hosting,firestore:rules,storage:rules`

## ğŸ’» Usage

1.  Open the deployed application URL.
2.  **Sign Up / Log In.**
3.  **Upload PDFs:** Files are processed, and embeddings are stored in Firestore.
4.  **Chat:** Ask questions. The backend retrieves vectors from Firestore, performs similarity search, and uses results to query Gemini.
5.  **Clear History / Reset Data.**

## âš™ï¸ Configuration Details

*   **`firebase.json`:** Defines deployment settings, including function runtimes and hosting rewrites.
*   **`firestore.rules` & `storage.rules`:** Security for your data.
*   **`functions/.env`:** (Local only) `GOOGLE_API_KEY`. **Do NOT commit.**
*   **`public/auth.js`:** Firebase web app config.
*   **`functions/main.py`:**
    *   Models for LLM (`gemini-1.5-flash-latest`) and embeddings (`models/text-embedding-004`) are defined here.
    *   Logic for interacting with Firestore to store/retrieve vectors.

## ğŸ“ File Structure

```firebase-rag-chatbot/
â”œâ”€â”€ functions/                  # Python backend
â”‚   â”œâ”€â”€ main.py                 # Flask app with RAG & Firestore vector logic
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â”œâ”€â”€ .env                    # Local env vars (gitignored)
â”‚   â””â”€â”€ ...
â”œâ”€â”€ public/                     # Frontend assets
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ style.css
â”‚   â”œâ”€â”€ app.js
â”‚   â””â”€â”€ auth.js
â”œâ”€â”€ .firebaserc
â”œâ”€â”€ firebase.json
â”œâ”€â”€ firestore.rules
â”œâ”€â”€ storage.rules
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md                   # This file
